{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronaksharma/Development/resume_genie/resgen_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from config import OPENAI_API_KEY, AZURE_OPENAI_API_KEY,AZURE_API_ENDPOINT,API_VERSION,AZURE_MODEL_NAME, MODEL_NAME\n",
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "# Azure OpenAI Client\n",
    "azure_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_API_KEY, \n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint = AZURE_API_ENDPOINT\n",
    "  )  \n",
    "\n",
    "# Helper Functions\n",
    "def get_embedding(client,text):\n",
    "    response = client.embeddings.create(\n",
    "        input = text,  \n",
    "        model=\"text-embedding-3-large\", # replace with small model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "  \n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    dot_product = sum(embedding1[i] * embedding2[i] for i in range(len(embedding1)))\n",
    "    magnitude1 = sum(x**2 for x in embedding1)**0.5\n",
    "    magnitude2 = sum(x**2 for x in embedding2)**0.5\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "  \n",
    "  \n",
    "def answer_question(client,persona, question, example=\"\"):\n",
    "  completion = client.chat.completions.create(\n",
    "    model=AZURE_MODEL_NAME,\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": f\"{persona}\"},\n",
    "      {\"role\": \"user\", \"content\": f\"{question}\"},\n",
    "      {\"role\": \"assistant\", \"content\": f\" You can use the following information as an example: {example}\"},\n",
    "    ],\n",
    "  )\n",
    "  return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "def add_embedding_to_db(collection_of_resumes_db,embedding,text,id):\n",
    "    collection_of_resumes_db.add(\n",
    "        embeddings = [embedding],\n",
    "        documents = [text],\n",
    "        ids = [id]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1314 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "      <th>number_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>1892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  number_tokens  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR           1314  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR           1314  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR           1759  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR            676  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR           1892  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the number of tokens\n",
    "resume_raw_data_df = pd.read_csv('Resume.csv')\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "resume_raw_data_df['number_tokens'] = resume_raw_data_df.Resume_str.apply(lambda x: len(tokenizer.encode(x)))\n",
    "resume_raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>number_tokens</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16852973</td>\n",
       "      <td>City  ,   State     Helps to develop policies...</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16852973</td>\n",
       "      <td>.         Advanced Medical Claims Analyst     ...</td>\n",
       "      <td>275</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16852973</td>\n",
       "      <td>ng and Advertising, working on public relation...</td>\n",
       "      <td>366</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16852973</td>\n",
       "      <td>ainte Genevieve Senior High   －   City  ,   St...</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  number_tokens  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...            318   \n",
       "1  16852973   City  ,   State     Helps to develop policies...            217   \n",
       "2  16852973  .         Advanced Medical Claims Analyst     ...            275   \n",
       "3  16852973  ng and Advertising, working on public relation...            366   \n",
       "4  16852973  ainte Genevieve Senior High   －   City  ,   St...            140   \n",
       "\n",
       "   index  \n",
       "0      1  \n",
       "1      2  \n",
       "2      3  \n",
       "3      4  \n",
       "4      5  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chunking data into roughly around 300 tokens\n",
    "\n",
    "# Using characters for chunking than tokens, as you can do list extraction based on character and not tokens\n",
    "resume_latest_data_df = pd.DataFrame(columns=[\"ID\", \"Resume_str\", \"number_tokens\"])\n",
    "\n",
    "# resume_raw_data_df['ID']\n",
    "max_tokens = 1200 # characters :  equivalent of 300 tokens \n",
    "counter = 0\n",
    "new_index=0\n",
    "\n",
    "for index, row in resume_raw_data_df.iterrows():\n",
    "    counter = 0\n",
    "    number_of_split = (row['number_tokens'])*4 // max_tokens # multiplying by 4 as each token is apporx 4 characters    \n",
    "    for i in range(number_of_split+2):\n",
    "        row_value = row['Resume_str'][counter: max_tokens+counter]\n",
    "        row_token =len(tokenizer.encode(row_value))\n",
    "        resume_latest_data_df.loc[new_index] = [resume_raw_data_df['ID'][index],row_value,row_token]\n",
    "        counter=max_tokens+counter\n",
    "        new_index+=1\n",
    "\n",
    "resume_latest_data_df[\"index\"] =[i for i in range(1, resume_latest_data_df.shape[0]+1)]\n",
    "resume_latest_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA\n",
    "# trial_Df = resume_latest_data_df.loc[resume_latest_data_df['ID'] == 18297650]\n",
    "# trial_Df\n",
    "# for index, row in trial_Df.iterrows():\n",
    "#     print(row['Resume_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "resume_latest_data_df['embeddings']=resume_latest_data_df.Resume_str.apply(lambda x: get_embedding(azure_client,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_latest_data_df.to_csv(\"resume_latest_data_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "resume_latest_data_df = pd.read_csv('resume_latest_data_df.csv', converters={'embeddings': literal_eval}) #convert string stored embeddings back to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15841"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRA\n",
    "len(resume_latest_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below 3 lines added for older python version\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=\"vector_database\",\n",
    "    settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")\n",
    "\n",
    "collection_of_resumes_db = chroma_client.get_or_create_collection(name=\"resume_vector\")\n",
    "\n",
    "# student_info = \"\"\"\n",
    "# Alex, a 19-year-old computer science sophomore with a 3.7 GPA\n",
    "# \"\"\"\n",
    "# colour_info = \"\"\"\n",
    "# Alex's favourite color is Red\n",
    "# \"\"\"\n",
    "# embedding_1 = get_embedding(azure_client,student_info)\n",
    "\n",
    "# embedding_2 = get_embedding(azure_client,colour_info)\n",
    "\n",
    "# collection_of_resumes_db.add(\n",
    "#     embeddings = [embedding_1],\n",
    "#     documents = [student_info],\n",
    "#     ids = [\"id1\"]\n",
    "# )\n",
    "\n",
    "for index, row in resume_latest_data_df.iterrows():\n",
    "    collection_of_resumes_db.add(\n",
    "        embeddings = [row[\"embeddings\"]],\n",
    "        documents = [row[\"Resume_str\"]],\n",
    "        ids = [str(row[\"index\"])]\n",
    "    )\n",
    "\n",
    "\n",
    "# resume_latest_data_df.apply(lambda x: add_embedding_to_db(collection_of_resumes_db, x.embeddings, x.Resume_str, str(x.index)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA\n",
    "# for index, row in resume_latest_data_df.iterrows():\n",
    "#     if row[\"index\"]==10 or row[\"index\"]==11:\n",
    "#         print(row['Resume_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15844"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXTRA\n",
    "# collection_of_resumes_db.peek()\n",
    "\n",
    "# all_documents = collection_of_resumes_db.get()['documents']\n",
    "# len(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Does any candidate already has Python coding experience? \n",
    "Please summarise their experience and provide their resume id. \n",
    "Also provide ids of other matching resumes\"\"\"\n",
    "\n",
    "questions_embedding = get_embedding(azure_client, question)\n",
    "\n",
    "results = collection_of_resumes_db.query(\n",
    "    query_embeddings=[questions_embedding],\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "best_result_document = results.get('documents')[0][0]\n",
    "\n",
    "best_result_index = int(results.get('ids')[0][0])\n",
    "best_result_id = resume_latest_data_df.loc[(resume_latest_data_df.index==best_result_index)]['ID']\n",
    "best_result_id = int(best_result_id.iloc[0])\n",
    "\n",
    "list_of_resume_ids = []\n",
    "for i in range(1,5):\n",
    "    other_result_index = int(results.get('ids')[0][i])\n",
    "    other_result_id = resume_latest_data_df.loc[(resume_latest_data_df.index==other_result_index)]['ID']\n",
    "    list_of_resume_ids.append((other_result_id.iloc[0]))\n",
    "\n",
    "string_of_resume_ids = ','.join(map(str, list_of_resume_ids))\n",
    "best_result = best_result_document + f\". The id of this specific resume is {best_result_id}. Also, other matching resumes are {string_of_resume_ids}\"\n",
    "print(best_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the candidate with the resume ID 50328713 has Python coding experience. Here's a summary of their experience:\n",
      "\n",
      "- The candidate has listed Python as one of their skills, indicating they are conversant with the language.\n",
      "- They have experience with machine learning tools and libraries such as Scikit-learn, Pandas, Seaborn, matplotlib, and basic working knowledge of TensorFlow.\n",
      "- They built a machine learning model using the XGBoost algorithm that achieved a 77.5% accuracy rate in the Kaggle Titanic challenge. This demonstrates practical application of their Python skills in a project setting.\n",
      "\n",
      "The resume ID for this candidate is 50328713.\n",
      "\n",
      "The other matching resumes you asked for are:\n",
      "\n",
      "- 32985311\n",
      "- 12011623\n",
      "- 14871762\n",
      "- 11813872\n",
      "\n",
      "Please note these ids are given without context or content; whether they have Python experience is not determinable from the information provided here. If their resumes also list Python as a skill or describe Python-based projects, those candidates would have Python coding experience. However, since the content of these resumes isn't provided, it's not possible to summarize their experience without reviewing the actual resumes.\n"
     ]
    }
   ],
   "source": [
    "persona = \"\"\"\n",
    "You are expert in reviewing resumes and identifying the best candidates for a role. You are an advisor to the HR team, especially in answering any queries\n",
    "\"\"\"\n",
    "persona=persona+best_result\n",
    "response = answer_question(client=azure_client, question=question, persona=persona)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Re-arrange the code and the function order\n",
    "- Update the name of the columns in the dataframe\n",
    "- Show both approaches ie with and without vector DB (without DB shows more mathematics)\n",
    "- Decide what to do with csvs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45ca95aefd86e0e372b2a57f2bf5af2dad170a3cafdf2ca91f8dc558701f3c9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
